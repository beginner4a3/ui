{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# üé§ Indic Parler TTS - Interactive Audio Quality Control\n",
                "\n",
                "**Features:**\n",
                "- 69 Named Speakers\n",
                "- 21 Indian Languages\n",
                "- 12 Emotion Tags\n",
                "- Full Audio Quality Controls\n",
                "\n",
                "Run the cells below to launch the interactive UI!"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 1Ô∏è‚É£ Check GPU"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "import torch\n",
                "\n",
                "if torch.cuda.is_available():\n",
                "    print(f\"‚úÖ GPU Available: {torch.cuda.get_device_name(0)}\")\n",
                "    print(f\"   Memory: {torch.cuda.get_device_properties(0).total_memory / 1e9:.2f} GB\")\n",
                "else:\n",
                "    print(\"‚ùå No GPU! Go to Runtime ‚Üí Change runtime type ‚Üí GPU\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 2Ô∏è‚É£ Clone Repository\n",
                "\n",
                "‚ö†Ô∏è **Replace `YOUR_USERNAME` with your actual GitHub username!**"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Clone your repository (update with your GitHub username)\n",
                "!git clone https://github.com/beginner4a3/ui.git\n",
                "%cd ui\n",
                "\n",
                "print(\"‚úÖ Repository cloned!\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 3Ô∏è‚É£ Install Dependencies"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Install all dependencies\n",
                "!pip install -q gradio>=4.0.0\n",
                "!pip install -q git+https://github.com/huggingface/parler-tts.git\n",
                "!pip install -q transformers accelerate soundfile scipy\n",
                "\n",
                "print(\"‚úÖ Dependencies installed!\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 4Ô∏è‚É£ Launch Interactive UI\n",
                "\n",
                "This will:\n",
                "1. Start the Gradio interface\n",
                "2. Generate a **public URL** you can access\n",
                "3. Let you control all audio quality settings!"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Launch the Gradio app\n",
                "!python app.py"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "---\n",
                "\n",
                "## üìã Alternative: Run Inline\n",
                "\n",
                "If you prefer to run the UI directly in this notebook (without cloning):"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Skip this if you already ran the cells above\n",
                "# This is an alternative way to run the UI inline\n",
                "\n",
                "import torch\n",
                "import gradio as gr\n",
                "\n",
                "# Configuration\n",
                "SPEAKERS = [\"-- Random Voice --\", \"Divya (Hindi)\", \"Rohit (Hindi)\", \"Maya (Hindi)\", \n",
                "            \"Karan (Hindi)\", \"Aditi (Tamil)\", \"Sunita (Tamil)\", \"Anjali (Telugu)\"]\n",
                "EMOTIONS = [\"None\", \"Neutral\", \"Happy\", \"Sad\", \"Anger\", \"Fear\", \"Narration\", \"News\"]\n",
                "\n",
                "PITCH_MAP = {1: \"low-pitched\", 2: \"slightly low-pitched\", 3: \"moderate pitch\", \n",
                "             4: \"slightly high-pitched\", 5: \"high-pitched\"}\n",
                "SPEED_MAP = {1: \"slow pace\", 2: \"slightly slow pace\", 3: \"moderate pace\",\n",
                "             4: \"slightly fast pace\", 5: \"fast pace\"}\n",
                "EXPR_MAP = {1: \"monotone\", 2: \"slightly expressive\", 3: \"expressive and animated\"}\n",
                "\n",
                "# Model (global)\n",
                "model = None\n",
                "tokenizer = None\n",
                "desc_tokenizer = None\n",
                "device = None\n",
                "\n",
                "def load_model():\n",
                "    global model, tokenizer, desc_tokenizer, device\n",
                "    from parler_tts import ParlerTTSForConditionalGeneration\n",
                "    from transformers import AutoTokenizer\n",
                "    \n",
                "    device = \"cuda:0\" if torch.cuda.is_available() else \"cpu\"\n",
                "    dtype = torch.bfloat16 if torch.cuda.is_available() else torch.float32\n",
                "    \n",
                "    model = ParlerTTSForConditionalGeneration.from_pretrained(\n",
                "        \"ai4bharat/indic-parler-tts\", torch_dtype=dtype, attn_implementation=\"sdpa\"\n",
                "    ).to(device)\n",
                "    tokenizer = AutoTokenizer.from_pretrained(\"ai4bharat/indic-parler-tts\")\n",
                "    desc_tokenizer = AutoTokenizer.from_pretrained(model.config.text_encoder._name_or_path)\n",
                "    return f\"‚úÖ Model loaded on {device}\"\n",
                "\n",
                "def generate(text, speaker, gender, emotion, pitch, speed, expr, quality, noise, reverb):\n",
                "    global model, tokenizer, desc_tokenizer, device\n",
                "    if model is None:\n",
                "        return None, \"‚ùå Load model first!\"\n",
                "    \n",
                "    # Build description\n",
                "    if speaker != \"-- Random Voice --\":\n",
                "        name = speaker.split(\" (\")[0]\n",
                "        desc = f\"{name}'s voice is {EXPR_MAP[expr]} with a {PITCH_MAP[pitch]} tone at a {SPEED_MAP[speed]}\"\n",
                "    else:\n",
                "        desc = f\"A {gender} speaker with a {PITCH_MAP[pitch]} voice delivers {EXPR_MAP[expr]} speech at a {SPEED_MAP[speed]}\"\n",
                "    \n",
                "    if emotion != \"None\":\n",
                "        desc += f\" with a {emotion} tone\"\n",
                "    desc += f\". The recording is of {quality}, with {noise} audio and a {reverb} environment.\"\n",
                "    \n",
                "    # Generate\n",
                "    desc_ids = desc_tokenizer(desc, return_tensors=\"pt\").to(device)\n",
                "    text_ids = tokenizer(text, return_tensors=\"pt\").to(device)\n",
                "    \n",
                "    with torch.no_grad():\n",
                "        gen = model.generate(\n",
                "            input_ids=desc_ids.input_ids, attention_mask=desc_ids.attention_mask,\n",
                "            prompt_input_ids=text_ids.input_ids, prompt_attention_mask=text_ids.attention_mask\n",
                "        )\n",
                "    \n",
                "    audio = gen.cpu().numpy().squeeze()\n",
                "    return (model.config.sampling_rate, audio), f\"‚úÖ Done!\\n\\nüìù {desc}\"\n",
                "\n",
                "# Build UI\n",
                "with gr.Blocks(theme=gr.themes.Soft(primary_hue=\"purple\")) as app:\n",
                "    gr.Markdown(\"# üé§ Indic Parler TTS - Audio Quality Control\")\n",
                "    \n",
                "    with gr.Row():\n",
                "        load_btn = gr.Button(\"üöÄ Load Model\", variant=\"primary\")\n",
                "        status = gr.Textbox(label=\"Status\", value=\"‚è≥ Click Load Model\")\n",
                "    load_btn.click(load_model, outputs=status)\n",
                "    \n",
                "    with gr.Row():\n",
                "        with gr.Column():\n",
                "            text = gr.Textbox(label=\"Text\", value=\"Hello, welcome to Indic Parler TTS!\", lines=3)\n",
                "            speaker = gr.Dropdown(SPEAKERS, value=\"-- Random Voice --\", label=\"Speaker\")\n",
                "            with gr.Row():\n",
                "                gender = gr.Radio([\"female\", \"male\"], value=\"female\", label=\"Gender\")\n",
                "                emotion = gr.Dropdown(EMOTIONS, value=\"None\", label=\"Emotion\")\n",
                "            pitch = gr.Slider(1, 5, 3, step=1, label=\"Pitch\")\n",
                "            speed = gr.Slider(1, 5, 3, step=1, label=\"Speed\")\n",
                "            expr = gr.Slider(1, 3, 2, step=1, label=\"Expressivity\")\n",
                "            quality = gr.Radio([\"very high quality\", \"high quality\", \"good quality\"], \n",
                "                              value=\"very high quality\", label=\"Quality\")\n",
                "            noise = gr.Radio([\"very clear\", \"slightly noisy\", \"noisy\"], \n",
                "                            value=\"very clear\", label=\"Noise\")\n",
                "            reverb = gr.Radio([\"close-sounding\", \"slightly distant\", \"distant-sounding\"],\n",
                "                             value=\"close-sounding\", label=\"Reverb\")\n",
                "        \n",
                "        with gr.Column():\n",
                "            gen_btn = gr.Button(\"üéôÔ∏è Generate\", variant=\"primary\", size=\"lg\")\n",
                "            audio_out = gr.Audio(label=\"Output\")\n",
                "            status_out = gr.Textbox(label=\"Info\", lines=4)\n",
                "    \n",
                "    gen_btn.click(generate, \n",
                "                  [text, speaker, gender, emotion, pitch, speed, expr, quality, noise, reverb],\n",
                "                  [audio_out, status_out])\n",
                "\n",
                "app.launch(share=True)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "---\n",
                "\n",
                "## üìñ Audio Quality Settings Reference\n",
                "\n",
                "| Setting | Best for Clarity |\n",
                "|---------|------------------|\n",
                "| **Pitch** | Moderate (3) |\n",
                "| **Speed** | Moderate (3) |\n",
                "| **Expressivity** | Slightly Expressive (2) |\n",
                "| **Quality** | Very High Quality |\n",
                "| **Noise** | Very Clear |\n",
                "| **Reverb** | Close-Sounding |\n",
                "\n",
                "**Pro Tips:**\n",
                "- Use named speakers (Divya, Karan) for consistent voice\n",
                "- Add punctuation in text for natural pauses\n",
                "- Emotions work best with Tamil, Bengali, Hindi"
            ]
        }
    ],
    "metadata": {
        "accelerator": "GPU",
        "colab": {
            "gpuType": "T4",
            "provenance": []
        },
        "kernelspec": {
            "display_name": "Python 3",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "name": "python",
            "version": "3.10.12"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 4
}
